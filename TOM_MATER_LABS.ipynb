{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting buying Insurance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "description:\n",
    "Our old pal Mater was worried that during the pandemic people are not taking as much care of their vehicles as they are taking care of themselves.\n",
    "In order to find out the truth, he contacted his good friend Harsh who owns a big insurance company to find out whether this is true.\n",
    "Harsh being generous as always decided that the best way to do this is to find out whether or not people would buy insurance for their beloved cars.\n",
    "\n",
    "\n",
    "You have been provided with different features about people's previous insurance purchase and other details and you have to predict whether a person will be interested in buying the insurance or not.\n",
    "\n",
    "\n",
    "evaluation:\n",
    "The evaluation metric for this competition is Mean F1-Score.\n",
    "The F1 score, commonly used in information retrieval, measures\n",
    "accuracy using the statistics precision p and recall r.\n",
    "Precision is the ratio of true positives (tp) to all predicted positives (tp + fp).\n",
    "Recall is the ratio of true positives to all actual positives (tp + fn).\n",
    "\n",
    "Data fields:\n",
    "\n",
    "id - an anonymous id unique to a given person\n",
    "blood_group\n",
    "Gender\n",
    "Age\n",
    "Driving_license - whether or not person has a license\n",
    "Region_code- where person resides\n",
    "Previously_insured- whether the person was insured previously or not\n",
    "Vehicle_Age\n",
    "Vehicle_damage- If vehicle was ever damaged\n",
    "Annual Premiuim- Premium paid for insurance annually\n",
    "Policy_sales_channel\n",
    "Vintage-whether or not the vehicle is vintage\n",
    "Mother's_age\n",
    "Father's_age\n",
    "Accepted- Whether they accepted the insurance or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imporing neccesary libararies\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#importing training_dataset\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\m vasil ansari\\appdata\\local\\continuum\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#installing imblearn for smote\n",
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>blood_group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223723</td>\n",
       "      <td>O</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29223.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102674</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>28501.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15567</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>32590.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222937</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>245</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32565</td>\n",
       "      <td>B+</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>31821.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>59</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266771</th>\n",
       "      <td>349992</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>49840.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266772</th>\n",
       "      <td>260914</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31399.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266773</th>\n",
       "      <td>214966</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>21292.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266774</th>\n",
       "      <td>200722</td>\n",
       "      <td>B+</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>29448.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117</td>\n",
       "      <td>62</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266775</th>\n",
       "      <td>438772</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39092.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266776 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id blood_group  Gender  Age  Driving_License  Region_Code  \\\n",
       "0       223723           O  Female   23                1         18.0   \n",
       "1       102674         AB-    Male   44                1         23.0   \n",
       "2        15567         AB+    Male   23                1         41.0   \n",
       "3       222937           O    Male   78                1         15.0   \n",
       "4        32565          B+  Female   25                1         44.0   \n",
       "...        ...         ...     ...  ...              ...          ...   \n",
       "266771  349992           O    Male   24                1         28.0   \n",
       "266772  260914         AB+    Male   41                1         14.0   \n",
       "266773  214966         AB+    Male   44                1          3.0   \n",
       "266774  200722          B+    Male   38                1         30.0   \n",
       "266775  438772           O    Male   48                1         41.0   \n",
       "\n",
       "        Previously_Insured Vehicle_Age Vehicle_Damage  Annual_Premium  \\\n",
       "0                        1    < 1 Year             No         29223.0   \n",
       "1                        0    1-2 Year            Yes         28501.0   \n",
       "2                        0    < 1 Year            Yes         32590.0   \n",
       "3                        1    1-2 Year             No          2630.0   \n",
       "4                        1    < 1 Year             No         31821.0   \n",
       "...                    ...         ...            ...             ...   \n",
       "266771                   1    < 1 Year             No         49840.0   \n",
       "266772                   0    1-2 Year            Yes         31399.0   \n",
       "266773                   0    1-2 Year            Yes         21292.0   \n",
       "266774                   1    1-2 Year            Yes         29448.0   \n",
       "266775                   0    1-2 Year            Yes         39092.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  accepted  \n",
       "0                      152.0       89          70          65         0  \n",
       "1                       26.0      111          61          66         1  \n",
       "2                      152.0       71          67          78         0  \n",
       "3                       14.0      245          74          63         0  \n",
       "4                      152.0       59          73          62         0  \n",
       "...                      ...      ...         ...         ...       ...  \n",
       "266771                 152.0       39          72          74         0  \n",
       "266772                  26.0       25          63          75         0  \n",
       "266773                  26.0       36          73          70         0  \n",
       "266774                  26.0      117          62          76         0  \n",
       "266775                  26.0      114          68          78         0  \n",
       "\n",
       "[266776 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.877437\n",
       "1    0.122563\n",
       "Name: accepted, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualising labels \n",
    "df['accepted'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26d4d411cc8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visulising columns\n",
    "sns.countplot(x='accepted',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26d4ebfabc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Gender'].value_counts(normalize = True).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting features and labels from training dataset\n",
    "features = df.iloc[:,[1,2,3,5,6,7,8,9,10,11,12,13]]\n",
    "result = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>AB-</th>\n",
       "      <th>B+</th>\n",
       "      <th>O</th>\n",
       "      <th>Male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29223.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28501.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>111</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32590.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>245</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31821.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>59</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266771</th>\n",
       "      <td>24</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>49840.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266772</th>\n",
       "      <td>41</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31399.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266773</th>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21292.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266774</th>\n",
       "      <td>38</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29448.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117</td>\n",
       "      <td>62</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266775</th>\n",
       "      <td>48</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39092.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266776 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Region_Code  Previously_Insured  Annual_Premium  \\\n",
       "0        23         18.0                   1         29223.0   \n",
       "1        44         23.0                   0         28501.0   \n",
       "2        23         41.0                   0         32590.0   \n",
       "3        78         15.0                   1          2630.0   \n",
       "4        25         44.0                   1         31821.0   \n",
       "...     ...          ...                 ...             ...   \n",
       "266771   24         28.0                   1         49840.0   \n",
       "266772   41         14.0                   0         31399.0   \n",
       "266773   44          3.0                   0         21292.0   \n",
       "266774   38         30.0                   1         29448.0   \n",
       "266775   48         41.0                   0         39092.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  AB-  B+  O  \\\n",
       "0                      152.0       89          70          65    0   0  1   \n",
       "1                       26.0      111          61          66    1   0  0   \n",
       "2                      152.0       71          67          78    0   0  0   \n",
       "3                       14.0      245          74          63    0   0  1   \n",
       "4                      152.0       59          73          62    0   1  0   \n",
       "...                      ...      ...         ...         ...  ...  .. ..   \n",
       "266771                 152.0       39          72          74    0   0  1   \n",
       "266772                  26.0       25          63          75    0   0  0   \n",
       "266773                  26.0       36          73          70    0   0  0   \n",
       "266774                  26.0      117          62          76    0   1  0   \n",
       "266775                  26.0      114          68          78    0   0  1   \n",
       "\n",
       "        Male  1  2  Yes  \n",
       "0          0  0  0    0  \n",
       "1          1  1  0    1  \n",
       "2          1  0  0    1  \n",
       "3          1  1  0    0  \n",
       "4          0  0  0    0  \n",
       "...      ... .. ..  ...  \n",
       "266771     1  0  0    0  \n",
       "266772     1  1  0    1  \n",
       "266773     1  1  0    1  \n",
       "266774     1  1  0    1  \n",
       "266775     1  1  0    1  \n",
       "\n",
       "[266776 rows x 15 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with categorical features\n",
    "va=pd.get_dummies(features['vehicle_age'],drop_first=True)\n",
    "bg=pd.get_dummies(features['blood_group'],drop_first=True)\n",
    "g=pd.get_dummies(features['Gender'],drop_first=True)\n",
    "vd=pd.get_dummies(features['Vehicle_Damage'],drop_first=True)\n",
    "\n",
    "features=features.drop(['blood_group','Gender','Vehicle_Age','Vehicle_Damage','vehicle_age'],axis=1)\n",
    "\n",
    "features=pd.concat([features,bg,g,va,vd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "266771    0\n",
       "266772    0\n",
       "266773    0\n",
       "266774    0\n",
       "266775    0\n",
       "Name: accepted, Length: 266776, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and test set for visualising accuracy on basis of f1-score\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    213420.000000\n",
       "mean          0.121826\n",
       "std           0.327085\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           1.000000\n",
       "Name: accepted, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    53356.000000\n",
       "mean         0.125515\n",
       "std          0.331306\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: accepted, dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>AB-</th>\n",
       "      <th>B+</th>\n",
       "      <th>O</th>\n",
       "      <th>Male</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154163</th>\n",
       "      <td>26</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37828.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21132</th>\n",
       "      <td>65</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>26</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33591.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33171.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>220</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162596</th>\n",
       "      <td>40</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20635.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>144</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237032</th>\n",
       "      <td>54</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44202.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187036</th>\n",
       "      <td>25</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28855.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117142</th>\n",
       "      <td>72</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23317.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>58</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45739.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>151</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117355</th>\n",
       "      <td>20</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>132</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213420 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Region_Code  Previously_Insured  Annual_Premium  \\\n",
       "154163   26         46.0                   0         37828.0   \n",
       "21132    65         48.0                   0          2630.0   \n",
       "5700     26         35.0                   1         33591.0   \n",
       "18731    22         13.0                   1         33171.0   \n",
       "162596   40         41.0                   0         20635.0   \n",
       "...     ...          ...                 ...             ...   \n",
       "237032   54         28.0                   0         44202.0   \n",
       "187036   25         30.0                   1         28855.0   \n",
       "117142   72         27.0                   0         23317.0   \n",
       "79192    58         28.0                   0         45739.0   \n",
       "117355   20         14.0                   0          2630.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  AB-  B+  O  \\\n",
       "154163                 152.0       78          73          73    0   0  0   \n",
       "21132                    4.0      194          72          65    0   0  0   \n",
       "5700                   152.0       74          71          64    1   0  0   \n",
       "18731                  152.0      220          71          64    1   0  0   \n",
       "162596                 124.0      144          77          62    1   0  0   \n",
       "...                      ...      ...         ...         ...  ...  .. ..   \n",
       "237032                 154.0      177          73          76    1   0  0   \n",
       "187036                 152.0      105          78          74    0   0  0   \n",
       "117142                  26.0       60          67          79    0   0  0   \n",
       "79192                   26.0      151          62          75    0   0  1   \n",
       "117355                 160.0      132          77          74    1   0  0   \n",
       "\n",
       "        Male  1  2  Yes  \n",
       "154163     0  0  0    1  \n",
       "21132      1  1  0    1  \n",
       "5700       0  0  0    0  \n",
       "18731      0  0  0    0  \n",
       "162596     0  1  0    0  \n",
       "...      ... .. ..  ...  \n",
       "237032     1  0  1    1  \n",
       "187036     1  0  0    0  \n",
       "117142     1  1  0    0  \n",
       "79192      0  0  1    1  \n",
       "117355     1  0  0    1  \n",
       "\n",
       "[213420 rows x 15 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampling using SMOTE,SMOTEENN,SMOTE-TOMEK,ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Working Procedure(SMOTE):\n",
    "At first the total no. of oversampling observations, N is set up. Generally, it is selected such that the binary class distribution is 1:1. But that could be tuned down based on need. Then the iteration starts by first selecting a positive class instance at random. Next, the KNN’s (by default 5) for that instance is obtained. At last, N of these K instances is chosen to interpolate new synthetic instances. To do that, using any distance metric the difference in distance between the feature vector and its neighbors is calculated. Now, this difference is multiplied by any random value in (0,1] and is added to the previous feature vector. This is pictorially represented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 187420, 1: 26000})\n",
      "After Counter({0: 187420, 1: 187420})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "counter =Counter(y_train)\n",
    "print('Before',counter)\n",
    "smt=SMOTE()\n",
    "X_train_sm,y_train_sm=smt.fit_resample(X_train,y_train)\n",
    "counter=Counter(y_train_sm)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 187420, 1: 26000})\n",
      "After Counter({1: 195028, 0: 187420})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "counter =Counter(y_train)\n",
    "print('Before',counter)\n",
    "ada=ADASYN(random_state=130)\n",
    "X_train_ada,y_train_ada=ada.fit_resample(X_train,y_train)\n",
    "counter=Counter(y_train_ada)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 187420, 1: 26000})\n",
      "After Counter({1: 167476, 0: 107122})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "counter =Counter(y_train)\n",
    "print('Before',counter)\n",
    "smenn=SMOTEENN()\n",
    "X_train_smenn,y_train_smenn=smenn.fit_resample(X_train,y_train)\n",
    "counter=Counter(y_train_smenn)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 187420, 1: 26000})\n",
      "After Counter({0: 184624, 1: 184624})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "counter =Counter(y_train)\n",
    "print('Before',counter)\n",
    "smtomek=SMOTETomek(random_state=139)\n",
    "X_train_smt,y_train_smt=smtomek.fit_resample(X_train,y_train)\n",
    "counter=Counter(y_train_smt)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_smenn, y_train_smenn)\n",
    "# Making predictions on unseen data\n",
    "predictions_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15556986, 0.00028442, 0.0516743 , 0.21899595, 0.05677301,\n",
       "       0.12006902, 0.05763726, 0.04040538, 0.04068047, 0.02201434,\n",
       "       0.02234606, 0.02288953, 0.00756382, 0.01420645, 0.00584086,\n",
       "       0.16304928])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x26d011ab048>,\n",
       "  <matplotlib.axis.XTick at 0x26d011db5c8>,\n",
       "  <matplotlib.axis.XTick at 0x26d011dcf08>,\n",
       "  <matplotlib.axis.XTick at 0x26d01232208>,\n",
       "  <matplotlib.axis.XTick at 0x26d01232548>,\n",
       "  <matplotlib.axis.XTick at 0x26d01232d88>,\n",
       "  <matplotlib.axis.XTick at 0x26d01237808>,\n",
       "  <matplotlib.axis.XTick at 0x26d0123c2c8>,\n",
       "  <matplotlib.axis.XTick at 0x26d0123cc48>,\n",
       "  <matplotlib.axis.XTick at 0x26d01237d88>,\n",
       "  <matplotlib.axis.XTick at 0x26d01240388>,\n",
       "  <matplotlib.axis.XTick at 0x26d01240ec8>,\n",
       "  <matplotlib.axis.XTick at 0x26d012438c8>,\n",
       "  <matplotlib.axis.XTick at 0x26d012473c8>,\n",
       "  <matplotlib.axis.XTick at 0x26d01247e88>,\n",
       "  <matplotlib.axis.XTick at 0x26d0124b988>],\n",
       " <a list of 16 Text xticklabel objects>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what features are the most important?\n",
    "plt.plot(rf.feature_importances_)\n",
    "plt.xticks(np.arange(X_train_sm.shape[1]), X_train_sm.columns.tolist(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 0.15556985698626463),\n",
       " ('Driving_License', 0.00028441607385735313),\n",
       " ('Region_Code', 0.05167430081911562),\n",
       " ('Previously_Insured', 0.21899594613103004),\n",
       " ('Annual_Premium', 0.056773010184589426),\n",
       " ('Policy_Sales_Channel', 0.12006902242318176),\n",
       " ('Vintage', 0.05763725790463974),\n",
       " ('mother_age', 0.040405376754215204),\n",
       " ('father_age', 0.04068046606025854),\n",
       " ('AB-', 0.022014341155907644),\n",
       " ('B+', 0.022346062574637945),\n",
       " ('O', 0.022889526656920775),\n",
       " ('Male', 0.007563820108269223),\n",
       " (1, 0.014206453966304553),\n",
       " (2, 0.0058408624632096205),\n",
       " ('Yes', 0.163049279737598)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a list of the features and their importance scores\n",
    "list(zip(features, rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     46659\n",
      "           1       0.31      0.35      0.33      6697\n",
      "\n",
      "    accuracy                           0.82     53356\n",
      "   macro avg       0.61      0.62      0.61     53356\n",
      "weighted avg       0.83      0.82      0.83     53356\n",
      "\n",
      "[[41552  5107]\n",
      " [ 4351  2346]]\n",
      "0.8262183218864934\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_rf))\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "# Under ROC curve\n",
    "prob_rf = rf.predict_proba(X_test)\n",
    "prob_rf = [p[1] for p in prob_rf]\n",
    "print(roc_auc_score(y_test, prob_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.89      0.90     46659\n",
    "           1       0.32      0.35      0.33      6697\n",
    "\n",
    "    accuracy                           0.82     53356\n",
    "   macro avg       0.61      0.62      0.62     53356\n",
    "weighted avg       0.83      0.82      0.83     53356\n",
    "\n",
    "[[41490  5169]\n",
    " [ 4320  2377]]\n",
    "0.8263150527249794"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTEENN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.78      0.85     46659\n",
    "           1       0.31      0.70      0.43      6697\n",
    "\n",
    "    accuracy                           0.77     53356\n",
    "   macro avg       0.63      0.74      0.64     53356\n",
    "weighted avg       0.87      0.77      0.80     53356\n",
    "\n",
    "[[36241 10418]\n",
    " [ 2006  4691]]\n",
    "0.8314088325624357"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE TOMEK:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.89      0.90     46659\n",
    "           1       0.32      0.36      0.34      6697\n",
    "\n",
    "    accuracy                           0.82     53356\n",
    "   macro avg       0.61      0.63      0.62     53356\n",
    "weighted avg       0.83      0.82      0.83     53356\n",
    "\n",
    "[[41496  5163]\n",
    " [ 4276  2421]]\n",
    "0.8269684051178658"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ada:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.89      0.90     46659\n",
    "           1       0.32      0.37      0.34      6697\n",
    "\n",
    "    accuracy                           0.82     53356\n",
    "   macro avg       0.61      0.63      0.62     53356\n",
    "weighted avg       0.83      0.82      0.83     53356\n",
    "\n",
    "[[41465  5194]\n",
    " [ 4241  2456]]\n",
    "0.8266885622196796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard Scaling/feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std_sm = scaler.fit_transform(X_train_sm)\n",
    "X_train_std_ada = scaler.fit_transform(X_train_ada)\n",
    "X_train_std_smt = scaler.fit_transform(X_train_smt)\n",
    "X_train_std_smenn = scaler.fit_transform(X_train_smenn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    234079\n",
       "1     32697\n",
       "Name: accepted, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority = df[df.accepted==1]\n",
    "df_majority = df[df.accepted==0]\n",
    "df['accepted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>blood_group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223723</td>\n",
       "      <td>O</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29223.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15567</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>32590.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222937</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>245</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32565</td>\n",
       "      <td>B+</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>31821.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>59</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>213918</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>36756.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>258</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266771</th>\n",
       "      <td>349992</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>49840.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266772</th>\n",
       "      <td>260914</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31399.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266773</th>\n",
       "      <td>214966</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>21292.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266774</th>\n",
       "      <td>200722</td>\n",
       "      <td>B+</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>29448.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117</td>\n",
       "      <td>62</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266775</th>\n",
       "      <td>438772</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39092.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234079 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id blood_group  Gender  Age  Driving_License  Region_Code  \\\n",
       "0       223723           O  Female   23                1         18.0   \n",
       "2        15567         AB+    Male   23                1         41.0   \n",
       "3       222937           O    Male   78                1         15.0   \n",
       "4        32565          B+  Female   25                1         44.0   \n",
       "5       213918         AB-    Male   67                1          8.0   \n",
       "...        ...         ...     ...  ...              ...          ...   \n",
       "266771  349992           O    Male   24                1         28.0   \n",
       "266772  260914         AB+    Male   41                1         14.0   \n",
       "266773  214966         AB+    Male   44                1          3.0   \n",
       "266774  200722          B+    Male   38                1         30.0   \n",
       "266775  438772           O    Male   48                1         41.0   \n",
       "\n",
       "        Previously_Insured Vehicle_Age Vehicle_Damage  Annual_Premium  \\\n",
       "0                        1    < 1 Year             No         29223.0   \n",
       "2                        0    < 1 Year            Yes         32590.0   \n",
       "3                        1    1-2 Year             No          2630.0   \n",
       "4                        1    < 1 Year             No         31821.0   \n",
       "5                        0    1-2 Year            Yes         36756.0   \n",
       "...                    ...         ...            ...             ...   \n",
       "266771                   1    < 1 Year             No         49840.0   \n",
       "266772                   0    1-2 Year            Yes         31399.0   \n",
       "266773                   0    1-2 Year            Yes         21292.0   \n",
       "266774                   1    1-2 Year            Yes         29448.0   \n",
       "266775                   0    1-2 Year            Yes         39092.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  accepted  \n",
       "0                      152.0       89          70          65         0  \n",
       "2                      152.0       71          67          78         0  \n",
       "3                       14.0      245          74          63         0  \n",
       "4                      152.0       59          73          62         0  \n",
       "5                      124.0      258          73          70         0  \n",
       "...                      ...      ...         ...         ...       ...  \n",
       "266771                 152.0       39          72          74         0  \n",
       "266772                  26.0       25          63          75         0  \n",
       "266773                  26.0       36          73          70         0  \n",
       "266774                  26.0      117          62          76         0  \n",
       "266775                  26.0      114          68          78         0  \n",
       "\n",
       "[234079 rows x 15 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    70500\n",
       "0    70500\n",
       "Name: accepted, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample with replacement to match majority class and get #reproducible results\n",
    "df_majority_upsampled = resample(df_majority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=70500,    \n",
    "                                 random_state=123)\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=70500,    \n",
    "                                 random_state=123)\n",
    " \n",
    "df_upsampled=pd.concat([df_minority_upsampled,df_majority_upsampled],axis=0)\n",
    "# Display new class counts\n",
    "df_upsampled.accepted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>blood_group</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163179</th>\n",
       "      <td>130109</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt; 2 Years</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40174.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>252</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128704</th>\n",
       "      <td>74426</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>31557.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>261</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228749</th>\n",
       "      <td>304440</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>40</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145444</th>\n",
       "      <td>312754</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>27930.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>207</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233560</th>\n",
       "      <td>69941</td>\n",
       "      <td>AB+</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33470.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>228</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205467</th>\n",
       "      <td>136131</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205080</th>\n",
       "      <td>11593</td>\n",
       "      <td>B+</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>34339.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>158</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204210</th>\n",
       "      <td>141372</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33924.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71584</th>\n",
       "      <td>13871</td>\n",
       "      <td>O</td>\n",
       "      <td>Male</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39442.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>123067</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24607.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id blood_group  Gender  Age  Driving_License  Region_Code  \\\n",
       "163179  130109         AB-  Female   45                1         35.0   \n",
       "128704   74426         AB-    Male   43                1         39.0   \n",
       "228749  304440           O    Male   50                1         29.0   \n",
       "145444  312754         AB-  Female   28                1         15.0   \n",
       "233560   69941         AB+  Female   39                1          3.0   \n",
       "...        ...         ...     ...  ...              ...          ...   \n",
       "205467  136131         AB-    Male   43                1         48.0   \n",
       "205080   11593          B+    Male   59                1         50.0   \n",
       "204210  141372           O    Male   72                1         28.0   \n",
       "71584    13871           O    Male   37                1         30.0   \n",
       "5772    123067         AB-    Male   27                1         36.0   \n",
       "\n",
       "        Previously_Insured Vehicle_Age Vehicle_Damage  Annual_Premium  \\\n",
       "163179                   0   > 2 Years            Yes         40174.0   \n",
       "128704                   1    1-2 Year             No         31557.0   \n",
       "228749                   0    1-2 Year            Yes          2630.0   \n",
       "145444                   0    1-2 Year            Yes         27930.0   \n",
       "233560                   0    1-2 Year            Yes         33470.0   \n",
       "...                    ...         ...            ...             ...   \n",
       "205467                   0    1-2 Year            Yes          2630.0   \n",
       "205080                   1    1-2 Year             No         34339.0   \n",
       "204210                   0    1-2 Year            Yes         33924.0   \n",
       "71584                    0    1-2 Year            Yes         39442.0   \n",
       "5772                     0    < 1 Year            Yes         24607.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  accepted  \n",
       "163179                  26.0      252          66          78         1  \n",
       "128704                 154.0      261          66          68         1  \n",
       "228749                 124.0       40          68          77         1  \n",
       "145444                 163.0      207          61          62         1  \n",
       "233560                  26.0      228          61          66         1  \n",
       "...                      ...      ...         ...         ...       ...  \n",
       "205467                 157.0       29          65          61         0  \n",
       "205080                  26.0      158          64          65         0  \n",
       "204210                 124.0       90          78          66         0  \n",
       "71584                  124.0       70          74          74         0  \n",
       "5772                   152.0       80          68          74         0  \n",
       "\n",
       "[141000 rows x 15 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test, normalize the new data set\n",
    "features_upsampled = df_upsampled.iloc[:,1:-1]\n",
    "result_upsampled = df_upsampled.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>AB-</th>\n",
       "      <th>B+</th>\n",
       "      <th>O</th>\n",
       "      <th>Male</th>\n",
       "      <th>&lt; 1 Year</th>\n",
       "      <th>&gt; 2 Years</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163179</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40174.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>252</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128704</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31557.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>261</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228749</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>40</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145444</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27930.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>207</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233560</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33470.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>228</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205467</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205080</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34339.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>158</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204210</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33924.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71584</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39442.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24607.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>80</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Driving_License  Region_Code  Previously_Insured  Annual_Premium  \\\n",
       "163179   45                1         35.0                   0         40174.0   \n",
       "128704   43                1         39.0                   1         31557.0   \n",
       "228749   50                1         29.0                   0          2630.0   \n",
       "145444   28                1         15.0                   0         27930.0   \n",
       "233560   39                1          3.0                   0         33470.0   \n",
       "...     ...              ...          ...                 ...             ...   \n",
       "205467   43                1         48.0                   0          2630.0   \n",
       "205080   59                1         50.0                   1         34339.0   \n",
       "204210   72                1         28.0                   0         33924.0   \n",
       "71584    37                1         30.0                   0         39442.0   \n",
       "5772     27                1         36.0                   0         24607.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  AB-  B+  O  \\\n",
       "163179                  26.0      252          66          78    1   0  0   \n",
       "128704                 154.0      261          66          68    1   0  0   \n",
       "228749                 124.0       40          68          77    0   0  1   \n",
       "145444                 163.0      207          61          62    1   0  0   \n",
       "233560                  26.0      228          61          66    0   0  0   \n",
       "...                      ...      ...         ...         ...  ...  .. ..   \n",
       "205467                 157.0       29          65          61    1   0  0   \n",
       "205080                  26.0      158          64          65    0   1  0   \n",
       "204210                 124.0       90          78          66    0   0  1   \n",
       "71584                  124.0       70          74          74    0   0  1   \n",
       "5772                   152.0       80          68          74    1   0  0   \n",
       "\n",
       "        Male  < 1 Year  > 2 Years  Yes  \n",
       "163179     0         0          1    1  \n",
       "128704     1         0          0    0  \n",
       "228749     1         0          0    1  \n",
       "145444     0         0          0    1  \n",
       "233560     0         0          0    1  \n",
       "...      ...       ...        ...  ...  \n",
       "205467     1         0          0    1  \n",
       "205080     1         0          0    0  \n",
       "204210     1         0          0    1  \n",
       "71584      1         0          0    1  \n",
       "5772       1         1          0    1  \n",
       "\n",
       "[141000 rows x 16 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "va=pd.get_dummies(features_upsampled['Vehicle_Age'],drop_first=True)\n",
    "bg=pd.get_dummies(features_upsampled['blood_group'],drop_first=True)\n",
    "g=pd.get_dummies(features_upsampled['Gender'],drop_first=True)\n",
    "vd=pd.get_dummies(features_upsampled['Vehicle_Damage'],drop_first=True)\n",
    "\n",
    "features_upsampled=features_upsampled.drop(['blood_group','Vehicle_Age','Gender','Vehicle_Damage'],axis=1)\n",
    "\n",
    "features_upsampled=pd.concat([features_upsampled,bg,g,va,vd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69     14166\n",
      "           1       0.68      1.00      0.81     14034\n",
      "\n",
      "    accuracy                           0.76     28200\n",
      "   macro avg       0.84      0.76      0.75     28200\n",
      "weighted avg       0.84      0.76      0.75     28200\n",
      "\n",
      "[[ 7453  6713]\n",
      " [   35 13999]]\n",
      "0.8350179887247065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_upsampled, X_test_upsampled, y_train_upsampled, y_test_upsampled = train_test_split(features_upsampled, result_upsampled, test_size = 0.2, random_state = 14)\n",
    "X_train_std_upsampled = scaler.fit_transform(X_train_upsampled)\n",
    "X_test_std_upsampled = scaler.fit_transform(X_test_upsampled)\n",
    "# new log model for upsampled data\n",
    "logmodel_upsampled = LogisticRegression(solver='liblinear')\n",
    "logmodel_upsampled.fit(X_train_std_upsampled, y_train_upsampled)\n",
    "predictions_y_2_upsampled = logmodel_upsampled.predict_proba(X_test_std_upsampled)\n",
    "from sklearn.preprocessing import binarize\n",
    "predictions_y_2_upsampled=binarize(predictions_y_2_upsampled,0.1)[:,1]\n",
    "\n",
    "print(classification_report(y_test_upsampled, predictions_y_2_upsampled))\n",
    "print(confusion_matrix(y_test_upsampled, predictions_y_2_upsampled))\n",
    "accuracy_score(y_test_upsampled, predictions_y_2_upsampled)\n",
    "# Under ROC curve\n",
    "prob_y_2_upsampled = logmodel_upsampled.predict_proba(X_test_std_upsampled)\n",
    "prob_y_2_upsampled = [p[1] for p in prob_y_2_upsampled]\n",
    "print(roc_auc_score(y_test_upsampled, prob_y_2_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.1 threshold the Confusion Matrix is  \n",
      " [[ 7453  6713]\n",
      " [   35 13999]] \n",
      " with 21452 correct predictions and 35 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9975060567193957 Specificity:  0.5261188761824086 \n",
      "\n",
      "\n",
      "\n",
      "With 0.2 threshold the Confusion Matrix is  \n",
      " [[ 7980  6186]\n",
      " [  140 13894]] \n",
      " with 21874 correct predictions and 140 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.990024226877583 Specificity:  0.5633206268530284 \n",
      "\n",
      "\n",
      "\n",
      "With 0.3 threshold the Confusion Matrix is  \n",
      " [[ 8286  5880]\n",
      " [  243 13791]] \n",
      " with 22077 correct predictions and 243 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9826849080803762 Specificity:  0.5849216433714528 \n",
      "\n",
      "\n",
      "\n",
      "With 0.4 threshold the Confusion Matrix is  \n",
      " [[ 8422  5744]\n",
      " [  308 13726]] \n",
      " with 22148 correct predictions and 308 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9780532991306826 Specificity:  0.5945220951574192 \n",
      "\n",
      "\n",
      "\n",
      "With 0.5 threshold the Confusion Matrix is  \n",
      " [[ 8438  5728]\n",
      " [  336 13698]] \n",
      " with 22136 correct predictions and 336 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9760581445061992 Specificity:  0.5956515600734152 \n",
      "\n",
      "\n",
      "\n",
      "With 0.6 threshold the Confusion Matrix is  \n",
      " [[ 9903  4263]\n",
      " [ 2302 11732]] \n",
      " with 21635 correct predictions and 2302 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.8359697876585436 Specificity:  0.6990681914443032 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logmodel_lowering = LogisticRegression(solver='liblinear')\n",
    "logmodel_lowering.fit(X_train_std_upsampled, y_train_upsampled)\n",
    "from sklearn.preprocessing import binarize\n",
    "for i in range(1,7):\n",
    "    cm2=0\n",
    "    predictions_y_2_lowering = logmodel_lowering.predict_proba(X_test_std_upsampled)\n",
    "    y_pred2_lowering=binarize(predictions_y_2_lowering,i/10)[:,1]\n",
    "    cm2=confusion_matrix(y_test_upsampled,y_pred2_lowering)\n",
    "    print ('With',i/10,'threshold the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "n_estimators = [50, 60,80,100]\n",
    "max_samples = [0.8,1.0]\n",
    "param_grid = dict(n_estimators = n_estimators, max_samples=max_samples)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "grid_search_b = GridSearchCV(BaggingClassifier(), param_grid, scoring = 'roc_auc', n_jobs = -1, cv=kfold, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 26.5min finished\n"
     ]
    }
   ],
   "source": [
    "result_gcv_b=grid_search_b.fit(X_train_std_smenn,y_train_smenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.969826 using {'max_samples': 1.0, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (result_gcv_b.best_score_, result_gcv_b.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bclassifier=BaggingClassifier(max_samples=1.0,n_estimators=100)\n",
    "bclassifier.fit(X_train_std_smt,y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bagg = bclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83     46659\n",
      "           1       0.19      0.37      0.26      6697\n",
      "\n",
      "    accuracy                           0.73     53356\n",
      "   macro avg       0.55      0.58      0.54     53356\n",
      "weighted avg       0.81      0.73      0.76     53356\n",
      "\n",
      "0.7232922325837552\n",
      "the Confusion Matrix is  \n",
      " [[36278 10381]\n",
      " [ 4201  2496]] \n",
      " with 38774 correct predictions and 4201 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.3727041959086158 Specificity:  0.7775134486379905 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_bagg))\n",
    "cm2=confusion_matrix(y_test, predictions_bagg)\n",
    "# Under ROC curve\n",
    "prob_bagg = bclassifier.predict_proba(X_test)\n",
    "prob_bagg = [p[1] for p in prob_bagg]\n",
    "print(roc_auc_score(y_test, prob_bagg))\n",
    "print ('the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(solver='liblinear')\n",
    "logmodel.fit(X_train_std_sm, y_train_sm)\n",
    "predictions_y_2 = logmodel.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69     46659\n",
      "           1       0.23      1.00      0.38      6697\n",
      "\n",
      "    accuracy                           0.59     53356\n",
      "   macro avg       0.62      0.76      0.54     53356\n",
      "weighted avg       0.90      0.59      0.65     53356\n",
      "\n",
      "[[24768 21891]\n",
      " [   32  6665]]\n",
      "0.7899113268538008\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_y_2))\n",
    "print(confusion_matrix(y_test, predictions_y_2))\n",
    "# Under ROC curve\n",
    "prob_y_2 = logmodel.predict_proba(X_test_std)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print(roc_auc_score(y_test, prob_y_2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.98      0.39      6697\n",
    "\n",
    "    accuracy                           0.61     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.61      0.67     53356\n",
    "\n",
    "[[25703 20956]\n",
    " [  101  6596]]\n",
    "0.8076626166092482"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smote enn:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.54      0.70     46659\n",
    "           1       0.23      0.99      0.38      6697\n",
    "\n",
    "    accuracy                           0.59     53356\n",
    "   macro avg       0.62      0.76      0.54     53356\n",
    "weighted avg       0.90      0.59      0.66     53356\n",
    "\n",
    "[[25015 21644]\n",
    " [   49  6648]]\n",
    "0.8148217323388446"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE TOMEK:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.98      0.39      6697\n",
    "\n",
    "    accuracy                           0.61     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.61      0.67     53356\n",
    "\n",
    "[[25759 20900]\n",
    " [  118  6579]]\n",
    "0.8082850465603005"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ADA:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.99      0.39      6697\n",
    "\n",
    "    accuracy                           0.60     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.60      0.67     53356\n",
    "\n",
    "[[25582 21077]\n",
    " [   75  6622]]\n",
    "0.8064739051409829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71     46659\n",
      "           1       0.24      0.99      0.39      6697\n",
      "\n",
      "    accuracy                           0.60     53356\n",
      "   macro avg       0.62      0.77      0.55     53356\n",
      "weighted avg       0.90      0.60      0.67     53356\n",
      "\n",
      "[[25605 21054]\n",
      " [   66  6631]]\n",
      "0.8087671710319344\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "logmodel.fit(X_train_std_sm, y_train_sm)\n",
    "predictions_y_3 = logmodel.predict(X_test_std)\n",
    "\n",
    "print(classification_report(y_test, predictions_y_3))\n",
    "print(confusion_matrix(y_test, predictions_y_3))\n",
    "accuracy_score(y_test, predictions_y_3)\n",
    "# Under ROC curve\n",
    "prob_y_3 = logmodel.predict_proba(X_test_std)\n",
    "prob_y_3 = [p[1] for p in prob_y_3]\n",
    "print(roc_auc_score(y_test, prob_y_3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE:              precision    recall  f1-score   support\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.98      0.39      6697\n",
    "\n",
    "    accuracy                           0.61     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.61      0.67     53356\n",
    "\n",
    "[[25703 20956]\n",
    " [  101  6596]]\n",
    "0.8076626166092482"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE ENN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.98      0.38      6697\n",
    "\n",
    "    accuracy                           0.60     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.60      0.67     53356\n",
    "\n",
    "[[25554 21105]\n",
    " [  104  6593]]\n",
    "0.8145982074878918"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smote tomek\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.98      0.39      6697\n",
    "\n",
    "    accuracy                           0.61     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.61      0.67     53356\n",
    "\n",
    "[[25759 20900]\n",
    " [  118  6579]]\n",
    "0.8082850465603005"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ADA:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      0.55      0.71     46659\n",
    "           1       0.24      0.99      0.39      6697\n",
    "\n",
    "    accuracy                           0.60     53356\n",
    "   macro avg       0.62      0.77      0.55     53356\n",
    "weighted avg       0.90      0.60      0.67     53356\n",
    "\n",
    "[[25629 21030]\n",
    " [   84  6613]]\n",
    "0.8064527450700483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>AB-</th>\n",
       "      <th>B+</th>\n",
       "      <th>O</th>\n",
       "      <th>Male</th>\n",
       "      <th>&lt; 1 Year</th>\n",
       "      <th>&gt; 2 Years</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154163</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37828.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21132</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>194</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33591.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18731</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33171.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>220</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162596</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20635.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>144</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237032</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44202.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>177</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187036</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28855.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117142</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23317.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45739.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>151</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117355</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>132</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213420 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Driving_License  Region_Code  Previously_Insured  Annual_Premium  \\\n",
       "154163   26                1         46.0                   0         37828.0   \n",
       "21132    65                1         48.0                   0          2630.0   \n",
       "5700     26                1         35.0                   1         33591.0   \n",
       "18731    22                1         13.0                   1         33171.0   \n",
       "162596   40                1         41.0                   0         20635.0   \n",
       "...     ...              ...          ...                 ...             ...   \n",
       "237032   54                1         28.0                   0         44202.0   \n",
       "187036   25                1         30.0                   1         28855.0   \n",
       "117142   72                1         27.0                   0         23317.0   \n",
       "79192    58                1         28.0                   0         45739.0   \n",
       "117355   20                1         14.0                   0          2630.0   \n",
       "\n",
       "        Policy_Sales_Channel  Vintage  mother_age  father_age  AB-  B+  O  \\\n",
       "154163                 152.0       78          73          73    0   0  0   \n",
       "21132                    4.0      194          72          65    0   0  0   \n",
       "5700                   152.0       74          71          64    1   0  0   \n",
       "18731                  152.0      220          71          64    1   0  0   \n",
       "162596                 124.0      144          77          62    1   0  0   \n",
       "...                      ...      ...         ...         ...  ...  .. ..   \n",
       "237032                 154.0      177          73          76    1   0  0   \n",
       "187036                 152.0      105          78          74    0   0  0   \n",
       "117142                  26.0       60          67          79    0   0  0   \n",
       "79192                   26.0      151          62          75    0   0  1   \n",
       "117355                 160.0      132          77          74    1   0  0   \n",
       "\n",
       "        Male  < 1 Year  > 2 Years  Yes  \n",
       "154163     0         1          0    1  \n",
       "21132      1         0          0    1  \n",
       "5700       0         1          0    0  \n",
       "18731      0         1          0    0  \n",
       "162596     0         0          0    0  \n",
       "...      ...       ...        ...  ...  \n",
       "237032     1         0          1    1  \n",
       "187036     1         1          0    0  \n",
       "117142     1         0          0    0  \n",
       "79192      0         0          1    1  \n",
       "117355     1         1          0    1  \n",
       "\n",
       "[213420 rows x 16 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84     46659\n",
      "           1       0.28      0.68      0.40      6697\n",
      "\n",
      "    accuracy                           0.74     53356\n",
      "   macro avg       0.61      0.72      0.62     53356\n",
      "weighted avg       0.86      0.74      0.78     53356\n",
      "\n",
      "[[35005 11654]\n",
      " [ 2125  4572]]\n",
      "0.8076080587010064\n"
     ]
    }
   ],
   "source": [
    "df['accepted'].value_counts(normalize = True)\n",
    "weights = {0 : '0.848113', 1 : '0.151887'}\n",
    "logmodel_auto = LogisticRegression(class_weight = weights, solver = 'liblinear')\n",
    "logmodel_auto.fit(X_train_std_sm, y_train_sm)\n",
    "predictions_std_auto = logmodel_auto.predict(X_test_std)\n",
    "print(classification_report(y_test, predictions_std_auto))\n",
    "print(confusion_matrix(y_test, predictions_std_auto))\n",
    "accuracy_score(y_test, predictions_std_auto)\n",
    "# Under ROC curve\n",
    "prob_y_4 = logmodel.predict_proba(X_test_std)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(roc_auc_score(y_test, prob_y_4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.75      0.84     46659\n",
    "           1       0.28      0.68      0.40      6697\n",
    "\n",
    "    accuracy                           0.74     53356\n",
    "   macro avg       0.61      0.72      0.62     53356\n",
    "weighted avg       0.86      0.74      0.78     53356\n",
    "\n",
    "[[35009 11650]\n",
    " [ 2122  4575]]\n",
    "0.8064527450700483"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smote tomek:      precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.75      0.84     46659\n",
    "           1       0.28      0.69      0.40      6697\n",
    "\n",
    "    accuracy                           0.74     53356\n",
    "   macro avg       0.61      0.72      0.62     53356\n",
    "weighted avg       0.86      0.74      0.78     53356\n",
    "\n",
    "[[34976 11683]\n",
    " [ 2102  4595]]\n",
    "0.8064527450700483"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTE ENN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.65      0.78     46659\n",
    "           1       0.26      0.87      0.40      6697\n",
    "\n",
    "    accuracy                           0.68     53356\n",
    "   macro avg       0.62      0.76      0.59     53356\n",
    "weighted avg       0.88      0.68      0.73     53356\n",
    "\n",
    "[[30239 16420]\n",
    " [  864  5833]]\n",
    "0.8064527450700483"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ADA:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.74      0.83     46659\n",
    "           1       0.28      0.70      0.40      6697\n",
    "\n",
    "    accuracy                           0.74     53356\n",
    "   macro avg       0.61      0.72      0.62     53356\n",
    "weighted avg       0.86      0.74      0.78     53356\n",
    "\n",
    "[[34537 12122]\n",
    " [ 1984  4713]]\n",
    "0.8064527450700483"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier with best suitable weights for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "weights = np.linspace(0.03, 0.97, 55)\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=LogisticRegression(solver='liblinear'),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    cv=5,n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = gsc.fit(X_train_std_ada, y_train_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.882962962962963, 1: 0.11703703703703705}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters : %s\" % grid_result.best_params_) #smenn,ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89     46659\n",
      "           1       0.31      0.42      0.36      6697\n",
      "\n",
      "    accuracy                           0.81     53356\n",
      "   macro avg       0.61      0.64      0.62     53356\n",
      "weighted avg       0.84      0.81      0.82     53356\n",
      "\n",
      "the Confusion Matrix is  \n",
      " [[40495  6164]\n",
      " [ 3897  2800]] \n",
      " with 43295 correct predictions and 3897 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.4180976556667164 Specificity:  0.8678925823528151 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# passing weights found above\n",
    "rf_w = RandomForestClassifier(class_weight = {0: 0.882962962962963, 1: 0.11703703703703705})\n",
    "rf_w.fit(X_train_ada, y_train_ada)\n",
    "predictions_rf_w=rf_w.predict(X_test)\n",
    "print(classification_report(y_test, predictions_rf_w))\n",
    "cm2=confusion_matrix(y_test, predictions_rf_w)\n",
    "accuracy_score(y_test, predictions_rf_w)\n",
    "print ('the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.87      0.89     46659\n",
    "           1       0.32      0.41      0.36      6697\n",
    "\n",
    "    accuracy                           0.82     53356\n",
    "   macro avg       0.62      0.64      0.63     53356\n",
    "weighted avg       0.84      0.82      0.83     53356\n",
    "\n",
    "[[40734  5925]\n",
    " [ 3930  2767]]\n",
    "0.8152972486693155\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SMOTEENN:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.76      0.84     46659\n",
    "           1       0.31      0.75      0.43      6697\n",
    "\n",
    "    accuracy                           0.76     53356\n",
    "   macro avg       0.63      0.75      0.64     53356\n",
    "weighted avg       0.87      0.76      0.79     53356\n",
    "\n",
    "[[35333 11326]\n",
    " [ 1693  5004]]\n",
    "0.7559974510832896"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "smote tomek:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.87      0.89     46659\n",
    "           1       0.32      0.41      0.36      6697\n",
    "\n",
    "    accuracy                           0.81     53356\n",
    "   macro avg       0.61      0.64      0.63     53356\n",
    "weighted avg       0.84      0.81      0.82     53356\n",
    "\n",
    "[[40693  5966]\n",
    " [ 3921  2776]]\n",
    "0.8146975035609866"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ADA:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.87      0.89     46659\n",
    "           1       0.31      0.41      0.36      6697\n",
    "\n",
    "    accuracy                           0.81     53356\n",
    "   macro avg       0.61      0.64      0.62     53356\n",
    "weighted avg       0.84      0.81      0.82     53356\n",
    "\n",
    "[[40620  6039]\n",
    " [ 3927  2770]]\n",
    "0.8132168828247994"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic-Regression with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     46659\n",
      "           1       0.23      0.25      0.24      6697\n",
      "\n",
      "    accuracy                           0.80     53356\n",
      "   macro avg       0.56      0.57      0.56     53356\n",
      "weighted avg       0.81      0.80      0.81     53356\n",
      "\n",
      "0.788843168905213\n",
      "the Confusion Matrix is  \n",
      " [[41081  5578]\n",
      " [ 4999  1698]] \n",
      " with 42779 correct predictions and 4999 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.2535463640436016 Specificity:  0.880451788508112 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {0: '0.882962962962963', 1: '0.11703703703703705'}\n",
    "logmodel_auto_gridsearch = LogisticRegression(class_weight = weights, solver = 'liblinear')\n",
    "logmodel_auto_gridsearch.fit(X_train_std_ada, y_train_ada)\n",
    "predictions_std_auto_gridsearch = logmodel_auto_gridsearch.predict(X_test_std)\n",
    "print(classification_report(y_test, predictions_std_auto_gridsearch))\n",
    "cm2=confusion_matrix(y_test, predictions_std_auto_gridsearch)\n",
    "accuracy_score(y_test, predictions_std_auto_gridsearch)\n",
    "# Under ROC curve\n",
    "prob_y_3_gridsearch = logmodel_auto_gridsearch.predict_proba(X_test_std)\n",
    "prob_y_3_gridsearch= [p[1] for p in prob_y_3_gridsearch]\n",
    "print(roc_auc_score(y_test, prob_y_3_gridsearch))\n",
    "print ('the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.1 threshold the Confusion Matrix is  \n",
      " [[24366 22293]\n",
      " [   14  6683]] \n",
      " with 31049 correct predictions and 14 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9979095117216664 Specificity:  0.5222143637883366 \n",
      "\n",
      "\n",
      "\n",
      "With 0.2 threshold the Confusion Matrix is  \n",
      " [[26613 20046]\n",
      " [  109  6588]] \n",
      " with 33201 correct predictions and 109 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.98372405554726 Specificity:  0.5703722754452517 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.3 threshold the Confusion Matrix is  \n",
      " [[26843 19816]\n",
      " [  134  6563]] \n",
      " with 33406 correct predictions and 134 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9799910407645215 Specificity:  0.5753016567007437 \n",
      "\n",
      "\n",
      "\n",
      "With 0.4 threshold the Confusion Matrix is  \n",
      " [[35195 11464]\n",
      " [ 2682  4015]] \n",
      " with 39210 correct predictions and 2682 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.5995221741078095 Specificity:  0.7543024925523479 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.5 threshold the Confusion Matrix is  \n",
      " [[41081  5578]\n",
      " [ 4999  1698]] \n",
      " with 42779 correct predictions and 4999 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.2535463640436016 Specificity:  0.880451788508112 \n",
      "\n",
      "\n",
      "\n",
      "With 0.6 threshold the Confusion Matrix is  \n",
      " [[41798  4861]\n",
      " [ 5121  1576]] \n",
      " with 43374 correct predictions and 5121 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.23532925190383755 Specificity:  0.8958185987697979 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.6 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.7 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.7 threshold the Confusion Matrix is  \n",
      " [[41858  4801]\n",
      " [ 5125  1572]] \n",
      " with 43430 correct predictions and 5125 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.23473196953859937 Specificity:  0.8971045243147089 \n",
      "\n",
      "\n",
      "\n",
      "With 0.8 threshold the Confusion Matrix is  \n",
      " [[44177  2482]\n",
      " [ 5764   933]] \n",
      " with 45110 correct predictions and 5764 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.1393161116918023 Specificity:  0.9468055466255171 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.8 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.9 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.9 threshold the Confusion Matrix is  \n",
      " [[46659     0]\n",
      " [ 6697     0]] \n",
      " with 46659 correct predictions and 6697 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.0 Specificity:  1.0 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logmodel_lowering = LogisticRegression(solver='liblinear',class_weight={0: '0.882962962962963', 1: '0.11703703703703705'})\n",
    "logmodel_lowering.fit(X_train_std_ada, y_train_ada)\n",
    "from sklearn.preprocessing import binarize\n",
    "for i in range(1,10):\n",
    "    cm2=0\n",
    "    predictions_y_2_lowering = logmodel_lowering.predict_proba(X_test_std)\n",
    "    y_pred2_lowering=binarize(predictions_y_2_lowering,i/10)[:,1]\n",
    "    cm2=confusion_matrix(y_test,y_pred2_lowering)\n",
    "    print ('With',i/10,'threshold the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB-REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.616088\n",
      "[1]\tvalidation_0-error:0.43862\n",
      "[2]\tvalidation_0-error:0.414911\n",
      "[3]\tvalidation_0-error:0.411406\n",
      "[4]\tvalidation_0-error:0.320826\n",
      "[5]\tvalidation_0-error:0.322925\n",
      "[6]\tvalidation_0-error:0.299573\n",
      "[7]\tvalidation_0-error:0.347721\n",
      "[8]\tvalidation_0-error:0.384474\n",
      "[9]\tvalidation_0-error:0.350982\n",
      "[10]\tvalidation_0-error:0.350382\n",
      "[11]\tvalidation_0-error:0.345716\n",
      "[12]\tvalidation_0-error:0.377933\n",
      "[13]\tvalidation_0-error:0.402991\n",
      "[14]\tvalidation_0-error:0.399074\n",
      "[15]\tvalidation_0-error:0.437776\n",
      "[16]\tvalidation_0-error:0.423439\n",
      "[17]\tvalidation_0-error:0.40316\n",
      "[18]\tvalidation_0-error:0.40271\n",
      "[19]\tvalidation_0-error:0.421808\n",
      "RMSE: 0.502956\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.05,\n",
    "max_depth = 9, alpha = 10, n_estimators = 20)\n",
    "eval_set = [(X_test_std, y_test)]\n",
    "xg_reg.fit(X_train_std_ada, y_train_ada, eval_metric=\"error\", eval_set = eval_set, verbose = True)\n",
    "prediction_y_5=xg_reg.predict(X_test_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction_y_5))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 30, 40, 50, 60]\n",
    "max_depth = [2, 4, 5, 6, 7, 8]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(max_depth = max_depth, n_estimators = n_estimators, learning_rate=learning_rate)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 10)\n",
    "grid_search_xg = GridSearchCV(xg_reg, param_grid, scoring = 'roc_auc', n_jobs = -1, cv=kfold, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 44.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 54.1min finished\n"
     ]
    }
   ],
   "source": [
    "result_gcv_xgb = grid_search_xg.fit(X_train_std_ada, y_train_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.970204 using {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (result_gcv_xgb.best_score_, result_gcv_xgb.best_params_))\n",
    "means = result_gcv_xgb.cv_results_['mean_test_score']\n",
    "stds = result_gcv_xgb.cv_results_['std_test_score']\n",
    "params = result_gcv_xgb.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.592475\n"
     ]
    }
   ],
   "source": [
    "# rebuild using best params\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.3,\n",
    "max_depth = 8, alpha = 10, n_estimators = 60)\n",
    "eval_set = [(X_test_std, y_test)]\n",
    "xg_reg.fit(X_train_std_ada, y_train_ada, eval_metric=\"error\", eval_set = eval_set, verbose = False)\n",
    "prediction_y_5 = xg_reg.predict(X_test_std)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction_y_5))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06168026, 0.00264556, 0.85093343, ..., 0.00359445, 0.07036677,\n",
       "       0.99438125], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_y_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69     46659\n",
      "           1       0.23      0.99      0.38      6697\n",
      "\n",
      "    accuracy                           0.59     53356\n",
      "   macro avg       0.62      0.76      0.54     53356\n",
      "weighted avg       0.90      0.59      0.65     53356\n",
      "\n",
      "the Confusion Matrix is  \n",
      " [[24859 21800]\n",
      " [   67  6630]] \n",
      " with 31489 correct predictions and 67 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.9899955203822607 Specificity:  0.5327803853490216 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_y_5_01 = prediction_y_5\n",
    "prediction_y_5_01[prediction_y_5 > 0.5] = 1\n",
    "prediction_y_5_01[prediction_y_5 <= 0.5] = 0\n",
    "print(classification_report(y_test, prediction_y_5_01))\n",
    "cm2=confusion_matrix(y_test, prediction_y_5_01)\n",
    "accuracy_score(y_test, prediction_y_5_01)\n",
    "print ('the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST IMBALANCED CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: nan\n"
     ]
    }
   ],
   "source": [
    "# fit xgboost on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier()"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_smt,y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 0.640\n"
     ]
    }
   ],
   "source": [
    "# count examples in each class\n",
    "counter = Counter(y_train_smenn)\n",
    "# estimate scale_pos_weight value\n",
    "estimate = counter[0] / counter[1]\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     46659\n",
      "           1       0.30      0.54      0.39      6697\n",
      "\n",
      "    accuracy                           0.78     53356\n",
      "   macro avg       0.61      0.68      0.63     53356\n",
      "weighted avg       0.85      0.78      0.81     53356\n",
      "\n",
      "the Confusion Matrix is  \n",
      " [[38199  8460]\n",
      " [ 3070  3627]] \n",
      " with 41826 correct predictions and 3070 Type II errors( False Negatives) \n",
      "\n",
      " Sensitivity:  0.5415857846797073 Specificity:  0.8186844981675561 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_model=model.predict(X_test)\n",
    "print(classification_report(y_test, predictions_model))\n",
    "cm2=confusion_matrix(y_test, predictions_model)\n",
    "accuracy_score(y_test, predictions_model)\n",
    "print ('the Confusion Matrix is ','\\n',cm2,'\\n',\n",
    "            'with',cm2[0,0]+cm2[1,1],'correct predictions and',cm2[1,0],'Type II errors( False Negatives)','\\n\\n',\n",
    "          'Sensitivity: ',cm2[1,1]/(float(cm2[1,1]+cm2[1,0])),'Specificity: ',cm2[0,0]/(float(cm2[0,0]+cm2[0,1])),'\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting predictions for test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing dataset\n",
    "test_set=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting features of testing dataset\n",
    "X_test_=test_set.iloc[:,[1,2,3,5,6,7,8,9,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with categorical features\n",
    "#va=pd.get_dummies(X_test_['Vehicle_Age'],drop_first=True)\n",
    "bg=pd.get_dummies(X_test_['blood_group'],drop_first=True)\n",
    "#g=pd.get_dummies(X_test_['Gender'],drop_first=True)\n",
    "vd=pd.get_dummies(X_test_['Vehicle_Damage'],drop_first=True)\n",
    "\n",
    "X_test_=X_test_.drop(['blood_group','Vehicle_Damage'],axis=1)\n",
    "\n",
    "X_test_=pd.concat([X_test_,bg,vd],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_test_std_ = scaler.fit_transform(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for prediction\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting testing dataset\n",
    "predictions_test_ = model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M VASIL ANSARI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass threshold=0.3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "predictions_test_=binarize(predictions_test_,0.3)[:,1].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_ = rf_w.predict(X_test_).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to string type\n",
    "predictions_test_=predictions_test_.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted results\n",
    "predictions_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A submission file has been made\n"
     ]
    }
   ],
   "source": [
    "#Submiiting predictions\n",
    "def make_submission(prediction, sub_name):\n",
    "  my_submission = pd.DataFrame({'id':pd.read_csv('test.csv').id,'accepted':prediction})\n",
    "  my_submission.to_csv('{}'.format(sub_name),index=False)\n",
    "  print('A submission file has been made')\n",
    "make_submission(predictions_test_[:],'Submission_xgboost_3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
